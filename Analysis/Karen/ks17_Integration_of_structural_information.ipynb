{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run 'pymol_and_pdb_functions.py'\n",
    "start_pymol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karen/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "%run 'ks01_Data_import.ipynb'\n",
    "notebook_prefix = 'ks17'\n",
    "image_counter = Counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading 24-mer structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 37657.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 37675.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain C is discontinuous at line 37693.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain D is discontinuous at line 37711.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain E is discontinuous at line 37729.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain F is discontinuous at line 37747.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain G is discontinuous at line 37765.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain H is discontinuous at line 37783.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain I is discontinuous at line 37801.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain J is discontinuous at line 37819.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain K is discontinuous at line 37837.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain L is discontinuous at line 37855.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain M is discontinuous at line 37873.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain N is discontinuous at line 37891.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain O is discontinuous at line 37909.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain P is discontinuous at line 37927.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain Q is discontinuous at line 37945.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain R is discontinuous at line 37963.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain S is discontinuous at line 37981.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain T is discontinuous at line 37999.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain U is discontinuous at line 38017.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain V is discontinuous at line 38035.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain W is discontinuous at line 38053.\n",
      "  PDBConstructionWarning)\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/Bio/PDB/StructureBuilder.py:85: PDBConstructionWarning: WARNING: Chain X is discontinuous at line 38071.\n",
      "  PDBConstructionWarning)\n"
     ]
    }
   ],
   "source": [
    "his3_aligned_to_4lom_assembly_file = os.path.join(structure_predictions_folder, 'his3_24mer_assembly', \n",
    "                                                  'his3_swiss_aligned_to_4lom_assembly.pdb')\n",
    "structure = Bio.PDB.PDBParser().get_structure('his3_swiss_assembly', his3_aligned_to_4lom_assembly_file)\n",
    "model = structure[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distance_dict = OrderedDict()\n",
    "prefix = 'res_'\n",
    "\n",
    "constant_chain = model['A']\n",
    "\n",
    "positions_in_crystal = [r.id[1] for r in constant_chain.get_residues() if r.get_resname() in aa3]\n",
    "\n",
    "f = FloatProgress(min=0, max=len(list(constant_chain.get_residues())))\n",
    "display(f)\n",
    "\n",
    "for residue in constant_chain.get_residues():\n",
    "    if residue.get_resname() in aa3:\n",
    "        distance_dict[prefix + '%s' %residue.id[1]] = OrderedDict()\n",
    "\n",
    "        # distances to other residues\n",
    "        for position in positions_in_crystal:\n",
    "            distances = []\n",
    "            for other_chain in model.get_chains():\n",
    "                distances.append(get_distance_between_residues(residue, other_chain[position]))\n",
    "            distance_dict[prefix + '%s' %residue.id[1]][prefix + '%s' %position] = min(distances)\n",
    "\n",
    "        # distances to Mn ions\n",
    "        for position in [302, 303, 304]:\n",
    "            distances = []\n",
    "            for other_chain in model.get_chains():\n",
    "                other_residue = [r for r in other_chain if position == r.id[1]][0]\n",
    "                distances.append(get_distance_between_residues(residue, other_residue))\n",
    "            distance_dict[prefix + '%s' %residue.id[1]]['Mn_' + '%s' %position] = min(distances)\n",
    "        distance_dict[prefix + '%s' %residue.id[1]]['Mn_substrate_bound'] = min(\n",
    "            distance_dict[prefix + '%s' %residue.id[1]]['Mn_' + '302'],\n",
    "            distance_dict[prefix + '%s' %residue.id[1]]['Mn_' + '303'])\n",
    "            \n",
    "        # distances to substrate\n",
    "        for position in [301]:\n",
    "            distances = []\n",
    "            for other_chain in model.get_chains():\n",
    "                other_residue = [r for r in other_chain if position == r.id[1]][0]\n",
    "                distances.append(get_distance_between_residues(residue, other_residue))\n",
    "            distance_dict[prefix + '%s' %residue.id[1]]['substrate'] = min(distances)\n",
    "    f.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "structural_data = pd.DataFrame.from_dict(distance_dict, orient='index')\n",
    "new_index = sorted(structural_data.index.values, key=lambda s: int(s[4:]))\n",
    "structural_data = structural_data.reindex(new_index)\n",
    "structural_data['position'] = structural_data.index.map(lambda s: int(s[4:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondary structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# information from PyMol? using psico?\n",
    "# import psico\n",
    "# import psico.fullinit\n",
    "# import psico.helping\n",
    "# psico.helping.write_html_ref('psico-commands.html')\n",
    "\n",
    "helices = range (60,74) + range (89,109) + range (157,172) + range (185,205)\n",
    "sheets = range(5,12) + range(15,23) + range(52,55) + range(76,84) + range(117,125) + range(127,135) + range(138,145) + range(173,182)\n",
    "disordered = [position for position in range(1, len(Scer_Uniprot)) if position not in helices and position not in sheets]\n",
    "\n",
    "def get_secondary_structure(position):\n",
    "#     print position, position in helices, position in sheets\n",
    "    assert ~(position in helices and position in sheets)\n",
    "    if position in helices:\n",
    "        return 'helix'\n",
    "    elif position in sheets:\n",
    "        return 'sheet'\n",
    "    else:\n",
    "        return 'disordered'\n",
    "\n",
    "structural_data['secondary_structure'] = structural_data['position'].apply(get_secondary_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Interface residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ascii_letters_upper = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "\n",
    "cmd.reinitialize()\n",
    "cmd.load(his3_aligned_to_4lom_assembly_file, 'his3_swiss_assembly')\n",
    "\n",
    "interfaces = {}\n",
    "f = FloatProgress(min=0, max=len(list(itertools.combinations(range(24), 2))))\n",
    "display(f)\n",
    "for chain_index1, chain_index2 in (itertools.combinations(range(24), 2)):\n",
    "    chain1, chain2 = ascii_letters_upper[chain_index1], ascii_letters_upper[chain_index2]\n",
    "    returned = interfaceResidues('his3_swiss_assembly', cA = 'c. %s' %chain1, cB = 'c. %s' %chain2)\n",
    "    interfaces[chain1, chain2] = returned\n",
    "    f.value += 1\n",
    "    \n",
    "interface_residues = []\n",
    "for k,v in interfaces.items():\n",
    "    interface_residues.extend([e[1] for e in v])\n",
    "interface_residues = sorted(list(set([int(p) for p in interface_residues])))\n",
    "\n",
    "structural_data['interface'] = structural_data.index.map(lambda s: int(s[4:]) in interface_residues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sign epistasis from Lucas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Relative >>> absolute position\n",
    "position_translation = pd.read_table(files_dump_folder + 'position_translation.csv')\n",
    "position_translation.set_index('relative_position', inplace=True)\n",
    "\n",
    "def get_absolute_position(segment_number, relative_position):\n",
    "    return int(position_translation.iloc[relative_position]['S'+str(segment_number)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucas_sign_epistasis = pd.read_csv(files_dump_folder + 'sign_epistasis/' + 'lucas_sign_epistasis.csv')\n",
    "lucas_reciprocal_sign_epistasis = pd.read_csv(files_dump_folder + 'sign_epistasis/' + 'lucas_reciprocal_sign_epistasis.csv')\n",
    "\n",
    "p_value_threshold = 0.01\n",
    "filtered = lucas_sign_epistasis[lucas_sign_epistasis['pBon'] < p_value_threshold]\n",
    "sign_epistasis_positions = set.union(set(filtered['VarPos_absolute'].values), \n",
    "                                                set(filtered['SubPos_absolute'].values))\n",
    "sign_epistasis_positions = sorted([int(s) for s in sign_epistasis_positions])\n",
    "print len(sign_epistasis_positions), 'positions under sign epistasis'\n",
    "\n",
    "reciprocal_sign_epistasis_positions = set.union(set(lucas_reciprocal_sign_epistasis['position1'].values), \n",
    "                                                set(lucas_reciprocal_sign_epistasis['position1'].values))\n",
    "reciprocal_sign_epistasis_positions = sorted([int(s) for s in reciprocal_sign_epistasis_positions])\n",
    "print len(reciprocal_sign_epistasis_positions), 'positions under reciprocal sign epistasis'\n",
    "\n",
    "structural_data['lucas_sign_epistasis'] = structural_data.index.map(lambda s: int(s[4:]) in sign_epistasis_positions)\n",
    "structural_data['lucas_reciprocal_sign_epistasis'] = structural_data.index.map(lambda s: int(s[4:]) in reciprocal_sign_epistasis_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lucas_sign_epistasis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-db812397c880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_positions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlucas_sign_epistasis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVarPos_absolute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msign_positions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlucas_sign_epistasis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlucas_sign_epistasis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpBon\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVarPos_absolute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mno_sign_positions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_positions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mno_sign_positions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msign_positions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'sign_positions'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msign_positions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lucas_sign_epistasis' is not defined"
     ]
    }
   ],
   "source": [
    "all_positions = set(lucas_sign_epistasis.VarPos_absolute.values)\n",
    "sign_positions = set(lucas_sign_epistasis[lucas_sign_epistasis.pBon < 0.01].VarPos_absolute.values)\n",
    "no_sign_positions = all_positions.copy()\n",
    "no_sign_positions.difference_update(sign_positions)\n",
    "print 'sign_positions', sorted(list(sign_positions))\n",
    "print 'no_sign_positions', sorted(list(no_sign_positions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conservation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Scer_Uniprot = open(os.path.join(files_dump_folder, 'HIS3_saccharomyces_cerevisiae_from_Uniprot_P06633.txt')).read().rstrip()\n",
    "\n",
    "# numbering starts from zero\n",
    "conservation_scores = pd.read_table(files_dump_folder + 'conservation_score.csv')\n",
    "conservation_scores['positions_Uniprot_P06633'] = conservation_scores.position_in_alignment.apply(\n",
    "    lambda p: get_wt_position(p))\n",
    "\n",
    "structural_data['segment'] = structural_data['position'].apply(lambda p: conservation_scores.iloc[p-1]['segment'])\n",
    "structural_data['Scer_aa'] = structural_data['position'].apply(lambda p: Scer_Uniprot[p-1])\n",
    "\n",
    "structural_data['alignment_entropy'] = structural_data['position'].apply(lambda p: conservation_scores.iloc[p-1]['entropy'])\n",
    "structural_data['alignment_gap_fraction'] = structural_data['position'].apply(lambda p: conservation_scores.iloc[p-1]['gap_fr'])\n",
    "structural_data['conservation_score'] = structural_data['position'].apply(lambda p: conservation_scores.iloc[p-1]['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amino acid properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa_properties = pd.read_csv(files_dump_folder + 'properties_of_amino_acids.csv')\n",
    "structural_data = structural_data.reset_index().merge(aa_properties, left_on='Scer_aa' ,right_on='aa1', how='left').set_index('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impacts of mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_impacts_in_all_backgrounds(path_to_folder=None):\n",
    "    if not path_to_folder:\n",
    "        path_to_folder = os.path.join(files_dump_folder, 'impacts_of_mutations_in_all_backgrounds__full_lib', '')\n",
    "        print 'Since path to folder with hdfs was not provided, this is the path that will be used:\\n%s' %path_to_folder\n",
    "\n",
    "    f = FloatProgress(min=0, max=len(data.keys()))\n",
    "    display(f)\n",
    "\n",
    "    fit_dict = OrderedDict()\n",
    "    for segment in data:\n",
    "        segment_folder = os.path.join(path_to_folder, segment.split('_')[0], '')\n",
    "        files = [f for f in os.listdir(segment_folder)]\n",
    "        data_subset = data[segment].copy() \n",
    "        mutations = list(set(':'.join(data_subset.dropna(subset=['mut_list_Scer']).mut_list_Scer.values).split(':')))\n",
    "        mutations = sorted(list(mutations), key=lambda m: int(m[:-1]))\n",
    "        for mutation in mutations:\n",
    "            fn = 'impacts_of_mutation_%s.hdf' %(mutation)\n",
    "            if fn in files:\n",
    "                fit_dict[get_full_mutation(mutation)] = pd.read_hdf(segment_folder + fn)\n",
    "        f.value += 1\n",
    "    return fit_dict\n",
    "\n",
    "folder_with_fitness_impacts = check_dir(os.path.join(files_dump_folder, 'impacts_of_mutations_in_all_backgrounds', ''))\n",
    "fit_dict = read_impacts_in_all_backgrounds(path_to_folder=folder_with_fitness_impacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fitness_impacts = pd.DataFrame.from_dict(fit_dict, orient='index')\n",
    "fitness_impacts['position'] = fitness_impacts.index.map(lambda s: int(s[1:-1]))\n",
    "fitness_impacts['impact_mean'] = fitness_impacts.index.map(lambda m: fitness_impacts.loc[m].dropna().mean())\n",
    "fitness_impacts['impact_median'] = fitness_impacts.index.map(lambda m: fitness_impacts.loc[m].dropna().median())\n",
    "fitness_impacts['impact_std'] = fitness_impacts.index.map(lambda m: fitness_impacts.loc[m].dropna().std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impacts_summary = fitness_impacts.groupby('position')['impact_median'].agg([np.mean, np.median, np.std])\n",
    "impacts_summary.columns = ['impact_' + s for s in impacts_summary.columns]\n",
    "structural_data = structural_data.reset_index().merge(impacts_summary, how='left', left_on='position', right_index=True)\n",
    "structural_data = structural_data.set_index('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epistasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run 'ks08_Epistasis_in_all_backgrounds.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_empty_segment_position1_position2_defaultdict(segment_mutA_mutB_dict):\n",
    "    epistasis_by_positions = OrderedDict()\n",
    "    for segment in segment_mutA_mutB_dict:\n",
    "#         epistasis_by_positions[segment] = OrderedDict()\n",
    "        mutA_positions = set(mutA[:-1] for mutA, mutB in segment_mutA_mutB_dict[segment])\n",
    "        mutB_positions = set(mutB[:-1] for mutA, mutB in segment_mutA_mutB_dict[segment])\n",
    "        all_positions = sorted(list(set.union(mutA_positions, mutB_positions)), key=lambda s: int(s))\n",
    "        for position1 in all_positions:\n",
    "            epistasis_by_positions[position1] = OrderedDict()\n",
    "            for position2 in all_positions:\n",
    "                if position1 != position2:\n",
    "                    epistasis_by_positions[position1][position2] = defaultdict(list)\n",
    "    return epistasis_by_positions\n",
    "\n",
    "def fill_dictionary_with_values(dict_to_fill, segment_mutA_mutB_dict):\n",
    "    for segment in segment_mutA_mutB_dict:\n",
    "        for mutA, mutB in segment_mutA_mutB_dict[segment]:\n",
    "            posA, posB = mutA[:-1], mutB[:-1]\n",
    "            ep = segment_mutA_mutB_dict[segment][mutA, mutB]\n",
    "\n",
    "            if len(ep) > minimal_N:    \n",
    "                std = ep.std()\n",
    "                mean = ep.mean()\n",
    "                median = ep.median()\n",
    "                fraction_strong = 1. * len(ep[np.abs(ep) > strong_epistasis_threshold]) / len(ep)\n",
    "\n",
    "                dict_to_fill[posA][posB]['std'].append(std)\n",
    "                dict_to_fill[posB][posA]['std'].append(std)\n",
    "                \n",
    "                dict_to_fill[posA][posB]['mean'].append(mean)\n",
    "                dict_to_fill[posB][posA]['mean'].append(mean)\n",
    "\n",
    "                dict_to_fill[posA][posB]['median'].append(median)\n",
    "                dict_to_fill[posB][posA]['median'].append(median)\n",
    "\n",
    "                dict_to_fill[posA][posB]['fraction_strong'].append(fraction_strong)\n",
    "                dict_to_fill[posB][posA]['fraction_strong'].append(fraction_strong)\n",
    "                \n",
    "    return dict_to_fill\n",
    "\n",
    "def filter_position1_position2_dict(position1_position2_dict, what_to_look_at):\n",
    "    filtered = {}\n",
    "    for position in position1_position2_dict:\n",
    "        other_positions = position1_position2_dict[position].keys()\n",
    "        other_positions = [p for p in other_positions if len(position1_position2_dict[position][p][what_to_look_at]) > 0]\n",
    "        values = [np.mean(position1_position2_dict[position][p][what_to_look_at]) for p in other_positions \\\n",
    "                  if len(position1_position2_dict[position][p][what_to_look_at]) > 0]\n",
    "        filtered[position] = other_positions, values\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epdict__pos1_pos2 = get_empty_segment_position1_position2_defaultdict(ep_dict)\n",
    "epdict__pos1_pos2 = fill_dictionary_with_values(epdict__pos1_pos2, ep_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ep_mean_prefix = 'ep_mean_res_'\n",
    "\n",
    "def get_ep_slice(dict__pos1_pos2, function, ep_prefix):\n",
    "    d = {}\n",
    "    for position1 in dict__pos1_pos2:\n",
    "        for position2 in dict__pos1_pos2[position1]:\n",
    "            d[prefix + '%s' %position1] = {}\n",
    "            d[prefix + '%s' %position2] = {}\n",
    "\n",
    "    for position1 in dict__pos1_pos2:\n",
    "        for position2 in dict__pos1_pos2[position1]:\n",
    "            d[prefix + '%s' %position1][ep_prefix + '%s' %position2] = function(dict__pos1_pos2[position1][position2]['median'])\n",
    "            d[prefix + '%s' %position2][ep_prefix + '%s' %position1] = function(dict__pos1_pos2[position1][position2]['median'])\n",
    "    df = pd.DataFrame.from_dict(d, orient='index')\n",
    "    sorted_columns = sorted(df.columns, key=lambda s: int(s[len(ep_prefix):]))\n",
    "    df['position'] = df.index.map(lambda s: int(s[len(prefix):]))\n",
    "    return df\n",
    "\n",
    "structural_data = structural_data.reset_index().merge(get_ep_slice(epdict__pos1_pos2, np.mean, ep_mean_prefix), on='position', how='left')\n",
    "structural_data = structural_data.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title = 'Distance vs epistasis'\n",
    "plot_better()\n",
    "for position in structural_data1['position']:\n",
    "    try:\n",
    "        plt.scatter(structural_data1[prefix + '%s' %position], structural_data1[ep_mean_prefix + '%s' %position], \n",
    "                    edgecolor='none', color='purple', alpha=0.1)\n",
    "    except:\n",
    "        pass\n",
    "plt.ylim(-0.05, 0.05)\n",
    "plt.xlabel('Distance between positions, A')\n",
    "plt.ylabel('Average epistasis between positions\\nin all backgrounds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ddG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rosetta_folder = os.path.join(analysis_folder, 'Sasha', 'rosetta_runs', '')\n",
    "predicted_ddG = pd.read_table(rosetta_folder + 'run-170503-results-with-explicit-ddG.csv')\n",
    "predicted_ddG['mut_number'] = predicted_ddG['mut_list_Scer'].apply(lambda s: s.count(':')+1)\n",
    "predicted_ddG['mut_list_Scer_full'] = predicted_ddG['mut_list_Scer'].apply(convert_to_full_mutations)\n",
    "for aa_property in quantitative_properties:\n",
    "        predicted_ddG['Abs change in ' + aa_property.lower()] = predicted_ddG['mut_list_Scer_full'].apply(\n",
    "            lambda mut_comb: cumulative_property_change(mut_comb, aa_property))\n",
    "\n",
    "predicted_doubles = predicted_ddG[predicted_ddG['mut_number'] == 2].copy()\n",
    "predicted_singles = predicted_ddG[predicted_ddG['mut_number'] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_singles['position'] = predicted_singles['mut_list_Scer'].apply(lambda m: int(m[:-1]))\n",
    "mean_ddG = pd.DataFrame(predicted_singles.groupby('position')['ddG'].agg(np.mean))\n",
    "var_ddG = pd.DataFrame(predicted_singles.groupby('position')['ddG'].agg(np.var))\n",
    "\n",
    "structural_data = structural_data.reset_index().merge(mean_ddG, left_on='position', right_index=True, how='left')\n",
    "structural_data = structural_data.set_index('index')\n",
    "\n",
    "structural_data = structural_data.reset_index().merge(var_ddG, left_on='position', right_index=True, how='left')\n",
    "structural_data = structural_data.set_index('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "residuals_folder = os.path.join(analysis_folder, 'Katya', 'NN', 'residuals', '')\n",
    "fitness_potentials = OrderedDict()\n",
    "for segment in data:\n",
    "    fitness_potentials[segment] = pd.read_csv(residuals_folder + '%s.csv' %segment.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "structural_data.to_hdf(files_dump_folder + 'structural_data_for_predicted_24mer.hdf', 'data')\n",
    "structural_data.reset_index().to_csv(files_dump_folder + 'structural_data_for_predicted_24mer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'structural_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5c0bcd3064ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstructural_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'structural_data' is not defined"
     ]
    }
   ],
   "source": [
    "structural_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
