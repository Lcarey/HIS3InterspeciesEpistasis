{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karen/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/Users/karen/anaconda/lib/python2.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "from collections import OrderedDict\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "import gc\n",
    "import Bio.PDB\n",
    "from Bio import SeqIO\n",
    "from IPython.display import display\n",
    "from collections import Counter \n",
    "import itertools\n",
    "from IPython.html.widgets.widget_float import FloatProgress\n",
    "\n",
    "%matplotlib inline\n",
    "notebook_prefix = 'ks01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orienting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_folder_upstream(folder_name, max_iterations=50):\n",
    "    current_folder = os.getcwd()\n",
    "    counter = 0\n",
    "    while os.path.basename(current_folder) != folder_name and counter < max_iterations:\n",
    "        current_folder = os.path.dirname(current_folder)\n",
    "        counter += 1\n",
    "    if not counter < max_iterations:\n",
    "        return None\n",
    "    return current_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_folder_name = 'HIS3InterspeciesEpistasis'\n",
    "root_folder = find_folder_upstream(root_folder_name)\n",
    "if not root_folder:\n",
    "    print 'Did not find root folder for our github repository.\\nPlease run \"ks01\" notebook from a script inside the HIS3InterspeciesEpistasis folder!'\n",
    "\n",
    "data_folder = os.path.join(root_folder, 'Data', '')\n",
    "small_tables_folder = os.path.join(root_folder, 'Data_Small_Tables', '')\n",
    "analysis_folder = os.path.join(root_folder, 'Analysis', '')\n",
    "karen_folder = os.path.join(analysis_folder, 'Karen', '')\n",
    "figures_folder = os.path.join(karen_folder, 'figures', '')\n",
    "files_dump_folder = os.path.join(karen_folder, 'files_dump', '')\n",
    "structure_predictions_folder = os.path.join(files_dump_folder, 'structure_predictions', '')\n",
    "structure_visualizations_folder = os.path.join(files_dump_folder, 'structure_visualizations', '')\n",
    "pymol_sessions_folder = os.path.join(files_dump_folder, 'structure_visualizations/pymol_sessions/', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "old_dir = os.getcwd()\n",
    "os.chdir(karen_folder)\n",
    "%run 'functions_dump.py'\n",
    "os.chdir(old_dir)\n",
    "image_counter = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segment_colors_list = [('S1','#00aba9'), ('S2','#ff0097'), ('S3','#a200ff'), ('S4','#b8d000'), ('S5','#1ba1e2'), ('S6','#f09609'), \n",
    "('S7','#edc951'), ('S8','#cc2a36'), ('S9','#4f372d'), ('S10','#0c457d'), ('S11','#616161'), ('S12','#800080')]\n",
    "segment_colors = OrderedDict(segment_colors_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_segment_long_name_from_file(f):\n",
    "    return f[:-12]\n",
    "\n",
    "data_all = OrderedDict()\n",
    "files = [f for f in os.listdir(data_folder) if '.csv' in f]\n",
    "for f in sorted(files, key = lambda s: int(s.split('_')[0][1:])):\n",
    "    data_all[get_segment_long_name_from_file(f)] = pd.read_table(os.path.join(data_folder, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = 'Color code for segments'\n",
    "plt.figure(figsize=(1, 5))\n",
    "ax = plt.subplot(111)\n",
    "plt.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",  \n",
    "    labelbottom=\"off\", left=\"off\", right=\"off\", labelleft=\"off\")\n",
    "ax.spines[\"top\"].set_visible(False)  \n",
    "ax.spines[\"right\"].set_visible(False) \n",
    "ax.spines[\"bottom\"].set_visible(False)  \n",
    "ax.spines[\"left\"].set_visible(False) \n",
    "\n",
    "counter = 1\n",
    "for segment, color in sorted(segment_colors.items(), key=lambda s: int(s[0][1:]), reverse=True):\n",
    "    plt.plot(counter * np.array([1,1]), color=color, label=segment, lw=3)\n",
    "    plt.text(1.2, counter, segment, va='center')\n",
    "    counter += 1\n",
    "plt.xlim(-0.1, 1.8)\n",
    "plt.ylim(-0.1, counter + 0.1)\n",
    "plt.tight_layout()\n",
    "# save_image(image_counter, title, figures_folder, notebook_prefix)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_gaps(seq):\n",
    "    return ''.join([c for c in seq if c != '-'])\n",
    "\n",
    "def get_wt_position(position_in_alignment):\n",
    "    truncated_seq = remove_gaps(aligned_Scer[:position_in_alignment+1])\n",
    "    return len(truncated_seq)\n",
    "\n",
    "def relative_to_absolute_numbering(mutation, segment, df_with_data):\n",
    "    display(df_with_data[segment][df_with_data[segment].mut_list == mutation][['mut_list', 'mut_list_Scer']])\n",
    "    return df_with_data[segment][df_with_data[segment].mut_list == mutation].mut_list_Scer.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Scer_Uniprot = open(os.path.join(files_dump_folder, 'HIS3_saccharomyces_cerevisiae_from_Uniprot_P06633.txt')).read().rstrip()\n",
    "alignment_file = os.path.join(small_tables_folder, 'aa_seq.txt')\n",
    "for seq_record in SeqIO.parse(alignment_file, 'fasta'):\n",
    "    if seq_record.id == 'Scer':\n",
    "        aligned_Scer = str(seq_record.seq)\n",
    "        break\n",
    "assert remove_gaps(aligned_Scer) == Scer_Uniprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>segment</th>\n",
       "      <th>wt1</th>\n",
       "      <th>positions_alignment</th>\n",
       "      <th>len1</th>\n",
       "      <th>len2</th>\n",
       "      <th>start1</th>\n",
       "      <th>end1</th>\n",
       "      <th>wt2</th>\n",
       "      <th>start2</th>\n",
       "      <th>end2</th>\n",
       "      <th>start_Scer</th>\n",
       "      <th>end_Scer</th>\n",
       "      <th>positions_Uniprot_P06633</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1</td>\n",
       "      <td>EALGAVRGVK</td>\n",
       "      <td>[140, 141, 142, 143, 144, 145, 146, 147, 148, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>140</td>\n",
       "      <td>149</td>\n",
       "      <td>EALSRAVVDL</td>\n",
       "      <td>160</td>\n",
       "      <td>169</td>\n",
       "      <td>106</td>\n",
       "      <td>135</td>\n",
       "      <td>[106, 107, 108, 109, 110, 111, 112, 113, 114, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S2</td>\n",
       "      <td>SNRPYAVVE</td>\n",
       "      <td>[170, 171, 172, 173, 174, 175, 176, 177, 178, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>178</td>\n",
       "      <td>LSCEMIPHF</td>\n",
       "      <td>189</td>\n",
       "      <td>197</td>\n",
       "      <td>136</td>\n",
       "      <td>163</td>\n",
       "      <td>[136, 137, 138, 139, 140, 141, 142, 143, 144, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S3</td>\n",
       "      <td>LGLQREKVGD</td>\n",
       "      <td>[179, 180, 181, 182, 183, 184, 185, 186, 187, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>179</td>\n",
       "      <td>188</td>\n",
       "      <td>LESFAEA</td>\n",
       "      <td>198</td>\n",
       "      <td>204</td>\n",
       "      <td>145</td>\n",
       "      <td>170</td>\n",
       "      <td>[145, 146, 147, 148, 149, 150, 151, 152, 153, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Unnamed: 0 segment         wt1  \\\n",
       "0               S1  EALGAVRGVK   \n",
       "1               S2   SNRPYAVVE   \n",
       "2               S3  LGLQREKVGD   \n",
       "\n",
       "Unnamed: 0                                positions_alignment len1 len2  \\\n",
       "0           [140, 141, 142, 143, 144, 145, 146, 147, 148, ...   10   10   \n",
       "1           [170, 171, 172, 173, 174, 175, 176, 177, 178, ...    9    9   \n",
       "2           [179, 180, 181, 182, 183, 184, 185, 186, 187, ...   10    7   \n",
       "\n",
       "Unnamed: 0 start1 end1         wt2 start2 end2 start_Scer end_Scer  \\\n",
       "0             140  149  EALSRAVVDL    160  169        106      135   \n",
       "1             170  178   LSCEMIPHF    189  197        136      163   \n",
       "2             179  188     LESFAEA    198  204        145      170   \n",
       "\n",
       "Unnamed: 0                           positions_Uniprot_P06633  \n",
       "0           [106, 107, 108, 109, 110, 111, 112, 113, 114, ...  \n",
       "1           [136, 137, 138, 139, 140, 141, 142, 143, 144, ...  \n",
       "2           [145, 146, 147, 148, 149, 150, 151, 152, 153, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions = pd.read_table(os.path.join(small_tables_folder, 'positions.csv'))\n",
    "positions = positions.set_index('Unnamed: 0').transpose().reset_index()\n",
    "positions.rename(columns={'index' : 'segment', 'positions':'positions_alignment'}, inplace=True)\n",
    "positions.reset_index(drop=True, inplace=True)\n",
    "positions['positions_alignment'] = positions['positions_alignment'].apply(lambda s: ast.literal_eval(s))\n",
    "positions['positions_Uniprot_P06633'] = positions.positions_alignment.apply(lambda l: [get_wt_position(p) for p in l])\n",
    "segment_names = positions.segment.values # not explicitly sorted\n",
    "positions.to_csv(os.path.join(files_dump_folder, 'information_about_segments.csv'), index=False)\n",
    "positions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = 'Positions of segments according to Uniprot sequence'\n",
    "plot_better(grid='', height=2)\n",
    "old_y = 2\n",
    "for row in positions.iterrows():\n",
    "    for position in row[1].positions_Uniprot_P06633:\n",
    "        new_y = np.random.choice([1,2])\n",
    "        while new_y == old_y:\n",
    "            new_y = np.random.choice([1,2])\n",
    "    x = row[1].positions_Uniprot_P06633\n",
    "    plt.plot(x, [new_y for e in x], '.', lw=3, alpha=0.7, label=row[1].segment, color=segment_colors[row[1].segment])\n",
    "    plt.text(np.median(x), new_y + 0.3, row[1].segment)\n",
    "    old_y = new_y\n",
    "plt.ylim(0,4)\n",
    "plt.yticks([])\n",
    "plt.xlabel('Positions according to Uniprot sequence')\n",
    "plt.title(title)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping only the mutants carrying substitutions (no indels, no mutations in the unmutated \"central region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_mutations(muts):\n",
    "    if not muts > 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return muts.count(':') + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = OrderedDict()\n",
    "for k,v in data_all.items():\n",
    "    data[k] = v[(v.middle == 1) & (v.nogap == 1)].copy()\n",
    "    data[k]['mut_number'] = data[k].mut_list_Scer.apply(count_mutations)\n",
    "\n",
    "data_natural = OrderedDict()\n",
    "for k,v in data_all.items():\n",
    "    data_natural[k] = v[(v.middle == 1) & (v.nogap == 1) & (v.nat_lib == 1)].copy()\n",
    "    data_natural[k]['mut_number'] = data_natural[k].mut_list_Scer.apply(count_mutations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Killing data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding from_aa to notation of mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_full_mutation(mutation):\n",
    "    if mutation == '' or not mutation > 0:\n",
    "        return ''\n",
    "    position = int(mutation[:-1])\n",
    "    assert Scer_Uniprot[position-1] != mutation[-1]\n",
    "    return Scer_Uniprot[position-1] + mutation\n",
    "\n",
    "def convert_to_full_mutations(mut_combination):\n",
    "    if mut_combination == '' or not mut_combination > 0:\n",
    "        return ''\n",
    "    return ':'.join(get_full_mutation(mutation) for mutation in mut_combination.split(':'))\n",
    "    \n",
    "for segment in data:\n",
    "    data[segment]['mut_list_Scer_full'] = data[segment]['mut_list_Scer'].apply(convert_to_full_mutations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amino acid properties table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# amino acid codes\n",
    "aa_long = ['alanine', 'cysteine', 'aspartic acid', 'glutamic acid', 'phenylalanine', 'glycine', \n",
    "           'histidine', 'isoleucine', 'lysine', 'leucine', 'methionine', 'asparagine', 'proline',\n",
    "           'glutamine', 'arginine', 'serine', 'threonine', 'valine', 'tryptophan', 'tyrosine', 'unknown_aa'] \n",
    "aa1 = list(\"ACDEFGHIKLMNPQRSTVWYX\")\n",
    "aa3 = \"ALA CYS ASP GLU PHE GLY HIS ILE LYS LEU MET ASN PRO GLN ARG SER THR VAL TRP TYR XXX\".split()\n",
    "aa123 = dict(zip(aa1, aa3))\n",
    "aa321 = dict(zip(aa3, aa1))\n",
    "aa_full_to_1 = dict(zip(aa_long, aa1))\n",
    "aa_1_to_full = dict(zip(aa1, aa_long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Original table http://www.proteinsandproteomics.org/content/free/tables_1/table08.pdf\n",
    "\n",
    "aa_properties = pd.read_table(os.path.join(files_dump_folder, 'properties_of_amino_acids__unprocessed.csv'), sep=';')\n",
    "\n",
    "aa_properties['Fraction of buried among this aa'] = aa_properties['Percent buried residues'].apply(lambda s: float(s.split()[0]))\n",
    "aa_properties['Fraction of buried among all buried'] = aa_properties['Percent buried residues'].apply(lambda s: float(s.split()[1][1:-1]))\n",
    "\n",
    "aa_properties['Polarity average ranking'] = aa_properties['Ranking of amino acid polarities'].apply(lambda s: float(s.split()[0]))\n",
    "aa_properties['Polarity ranking (Radzicka and Wolfenden 1988)'] = aa_properties['Ranking of amino acid polarities'].apply(lambda s: float(s.split()[1][1:-1]))\n",
    "\n",
    "aa_properties['amino_acid'] = aa_properties['Amino acid residue'].apply(lambda s: s.lower())\n",
    "aa_properties.set_index('amino_acid', inplace=True)\n",
    "\n",
    "aa_properties.drop(['Unnamed: 8', 'Unnamed: 10', 'Percent buried residues', 'Ranking of amino acid polarities', 'Amino acid residue'], inplace=True, axis=1)\n",
    "aa_properties = aa_properties.astype(np.float, raise_on_error=False)\n",
    "\n",
    "quantitative_properties = [p for p in aa_properties.columns if 'pKa' not in p]\n",
    "\n",
    "def get_aa_properties_by_single_letter_code(aa_1):\n",
    "    return aa_properties.loc[aa_1_to_full[aa_1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa_properties['aa1'] = aa_properties.index.map(lambda s: aa_full_to_1[s])\n",
    "aa_properties['aa3'] = aa_properties['aa1'].apply(lambda s: aa123[s])\n",
    "aa_properties.to_csv(os.path.join(files_dump_folder, 'properties_of_amino_acids.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing mutations by properties of aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aa_property_change(mutation, aa_property):\n",
    "    assert aa_property in aa_properties.columns.values\n",
    "    if mutation == '':\n",
    "        return None\n",
    "    aa_from = mutation[0]\n",
    "    position = int(mutation[1:-1])\n",
    "    aa_to = mutation[-1]\n",
    "    properties_from = get_aa_properties_by_single_letter_code(aa_from)\n",
    "    properties_to = get_aa_properties_by_single_letter_code(aa_to)\n",
    "#     print mutation, properties_to[aa_property], properties_from[aa_property], properties_to[aa_property] - properties_from[aa_property]\n",
    "    return properties_to[aa_property] - properties_from[aa_property]\n",
    "\n",
    "\n",
    "precalculated_changes = {}\n",
    "for aa_property in quantitative_properties:\n",
    "    precalculated_changes[aa_property] = {}\n",
    "    for substitution in list(itertools.permutations([aa for aa in aa1 if aa != 'X'], 2)):\n",
    "        precalculated_changes[aa_property][substitution] = aa_property_change(substitution[0] + '123' + substitution[1], aa_property)        \n",
    "        \n",
    "def cumulative_property_change(mut_combination, aa_property, absolute_values=True, use_precalculated=True):\n",
    "    assert aa_property in aa_properties.columns.values\n",
    "    if mut_combination == '':\n",
    "        return None\n",
    "    changes = []\n",
    "    if use_precalculated:\n",
    "        for m in mut_combination.split(':'):\n",
    "            changes.append(precalculated_changes[aa_property][m[0], m[-1]])\n",
    "    else:\n",
    "        for m in mut_combination.split(':'):\n",
    "            changes.append(aa_property_change(m, aa_property))\n",
    "    if absolute_values:\n",
    "        return sum([np.abs(v) for v in changes])\n",
    "    else:\n",
    "        return sum(changes)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print 'Calculating changes in aa properties...'\n",
    "# for p in quantitative_properties:\n",
    "#     print '  ', p\n",
    "# sys.stdout.flush()\n",
    "\n",
    "f = FloatProgress(min=0, max=len(data.keys()))\n",
    "display(f)\n",
    "for segment in data:\n",
    "    for aa_property in quantitative_properties:\n",
    "        data[segment]['Abs change in ' + aa_property.lower()] = data[segment]['mut_list_Scer_full'].apply(\n",
    "            lambda mut_comb: cumulative_property_change(mut_comb, aa_property))\n",
    "    data[segment].to_hdf(os.path.join(files_dump_folder, 'processed_data', 'Data_dict_%s.hdf' %segment), 'data')\n",
    "    f.value += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique single mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1886 unique mutations across all segments\n",
      "238 natural unique mutations across all segments\n"
     ]
    }
   ],
   "source": [
    "unique_single_mutations = OrderedDict()\n",
    "for segment_name, segment_data in data.items():\n",
    "    without_wt = segment_data.dropna(subset=['mut_list_Scer'])\n",
    "    unique_single_mutations[segment_name] = set(':'.join(without_wt.mut_list_Scer.values).split(':'))\n",
    "unique_single_mutations['all_segments'] = set().union(*unique_single_mutations.values())\n",
    "# print len(unique_single_mutations['all_segments']), 'unique mutations across all segments'\n",
    "\n",
    "natural_unique_single_mutations = OrderedDict()\n",
    "for segment_name, segment_data in data_natural.items():\n",
    "    without_wt = segment_data.dropna(subset=['mut_list_Scer'])\n",
    "    natural_unique_single_mutations[segment_name] = set(':'.join(without_wt.mut_list_Scer.values).split(':'))\n",
    "natural_unique_single_mutations['all_segments'] = set().union(*natural_unique_single_mutations.values())\n",
    "# print len(natural_unique_single_mutations['all_segments']), 'natural unique mutations across all segments'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 231 single mutations with known effects. They are found in 120 positions\n"
     ]
    }
   ],
   "source": [
    "data_singles = OrderedDict()\n",
    "known_single_mutations = []\n",
    "for segment_name, segment_data in data.items():\n",
    "    data_singles[segment_name] = segment_data[segment_data.mut_list.str.count(':') == 0].copy()\n",
    "    data_singles[segment_name]['position_Scer'] = data_singles[segment_name]['mut_list_Scer'].apply(lambda s: int(s[:-1]))\n",
    "    known_single_mutations += set(':'.join(data_singles[segment_name].mut_list_Scer.values).split(':'))\n",
    "positions_with_known_mutations = set([int(m[:-1]) for m in known_single_mutations])\n",
    "# print 'There are %s single mutations with known effects. They are found in %s positions' % (len(known_single_mutations),\n",
    "#                                                                                             len(positions_with_known_mutations))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A dictionary containing fitness for every known single mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "single_mut_fitness_dict = {}\n",
    "for segment_data in data_singles.values():\n",
    "    single_mut_fitness_dict.update(dict(segment_data[['mut_list_Scer', 's']].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genotypes consisting of mutations with known effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wt_fitness = np.median([table[table.mut_number == 0].s.values[0] for table in data.values()])\n",
    "min_fitness = np.min([table.s.min() for table in data.values()])\n",
    "max_fitness = np.max([table.s.max() for table in data.values()])\n",
    "\n",
    "def mut_effect(fitness, wt_fitness=wt_fitness):\n",
    "    return fitness - wt_fitness\n",
    "\n",
    "def epistasis(single_mut_fitnesses, fitness_of_combination, wt_fitness=wt_fitness):\n",
    "    min_mut_effect = mut_effect(min_fitness, wt_fitness=wt_fitness) # has to be inside function for calculating foursome epistasis\n",
    "    max_mut_effect = mut_effect(max_fitness, wt_fitness=wt_fitness) # has to be inside function for calculating foursome epistasis\n",
    "    expected_mut_effect = sum([mut_effect(fitness, wt_fitness=wt_fitness) for fitness in single_mut_fitnesses])\n",
    "    expected_mut_effect = min(expected_mut_effect, max_mut_effect)\n",
    "    expected_mut_effect = max(expected_mut_effect, min_mut_effect)\n",
    "    return mut_effect(fitness_of_combination, wt_fitness=wt_fitness) - expected_mut_effect\n",
    "\n",
    "def epistasis_for_df(df):\n",
    "    mutations_combination = df['mut_list_Scer']\n",
    "    fitness_of_combination = df['s']\n",
    "    single_mut_fitnesses = []\n",
    "    for single_mutation in mutations_combination.split(':'):\n",
    "        single_mut_fitnesses.append(single_mut_fitness_dict[single_mutation])\n",
    "    return epistasis(single_mut_fitnesses, fitness_of_combination)\n",
    "\n",
    "def foursome_epistasis(panel, wt_mut_combination):\n",
    "    panel_slice = panel.major_xs(wt_mut_combination).loc['s']\n",
    "    wt_fitness = panel_slice['wild_type']\n",
    "    mutA_fitness = panel_slice['mutA']\n",
    "    mutB_fitness = panel_slice['mutB']\n",
    "    mutAB_fitness = panel_slice['mutAB']\n",
    "    return epistasis([mutA_fitness, mutB_fitness], mutAB_fitness, wt_fitness=wt_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_known_mutations_only = OrderedDict()\n",
    "for segment_name, segment_data in data.items():\n",
    "    without_wt = segment_data.dropna(subset=['mut_list_Scer'])\n",
    "    data_known_mutations_only[segment_name] = without_wt[without_wt.mut_list_Scer.apply(\n",
    "            lambda muts: consists_of_known_mutations(muts, data_singles[segment_name].mut_list_Scer.values))].copy()\n",
    "    data_known_mutations_only[segment_name]['epistasis'] = data_known_mutations_only[segment_name].apply(epistasis_for_df, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'positions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-259d47331712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# getting segment numbers for every position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mposition_to_segment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msegment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mposition\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'segment'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'positions_Uniprot_P06633'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mposition_to_segment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'positions' is not defined"
     ]
    }
   ],
   "source": [
    "# getting segment numbers for every position\n",
    "position_to_segment = {}\n",
    "for segment in positions.segment:\n",
    "    for position in positions.set_index('segment').loc[segment]['positions_Uniprot_P06633']:\n",
    "        position_to_segment[position] = segment\n",
    "        \n",
    "def get_segment(position_or_mutation):\n",
    "    if type(position_or_mutation) == int or type(position_or_mutation) == float:\n",
    "        return position_to_segment[int(position_or_mutation)] \n",
    "    elif type(position_or_mutation) == str:\n",
    "        return position_to_segment[int(position_or_mutation[:-1])] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now the following variables are available:\n",
      "\n",
      "- data: all data as a (sorted) dictionary in the form: 'segment_name': 'segment_data_as_pandas_dataframe'\n",
      "\n",
      "- unique_single_mutations: a dictionary with all single mutations for every segment\n",
      "\n",
      "- data_singles: a sorted dictionary in the form: 'segment_name': 'segment_data_as_pandas_dataframe' for genotypes containing a single substitution\n",
      "\n",
      "- single_mut_fitness_dict: a dictionary in the form: 'single mutation' : 'fitness'\n",
      "\n",
      "- data_known_mutations_only - a sorted dictionary in the form: 'segment_name': 'segment_data_as_pandas_dataframe', \n",
      "but only for those genotypes that consist of mutations with known effects (single mutant is measured).\n",
      "For this dictionary, epistasis is measured for every genotype.\n",
      "\n",
      "# # # # # # # # # # # # # # # # #\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print '''\n",
    "# \\nNow the following variables are available:\n",
    "\n",
    "# - data: all data as a (sorted) dictionary in the form: 'segment_name': 'segment_data_as_pandas_dataframe'\n",
    "\n",
    "# - unique_single_mutations: a dictionary with all single mutations for every segment\n",
    "\n",
    "# - data_singles: a sorted dictionary in the form: 'segment_name': 'segment_data_as_pandas_dataframe' for genotypes containing a single substitution\n",
    "\n",
    "# - single_mut_fitness_dict: a dictionary in the form: 'single mutation' : 'fitness'\n",
    "\n",
    "# - data_known_mutations_only: a sorted dictionary in the form: 'segment_name': 'segment_data_as_pandas_dataframe', \n",
    "# but only for those genotypes that consist of mutations with known effects (single mutant is measured).\n",
    "# For this dictionary, epistasis is measured for every genotype\n",
    "\n",
    "# - aa_properties: a pandas DataFrame summarizing properties of amino acids,\n",
    "# - precalculated_changes: dictionary with changes in amino acid properties calculated for every possible substitution\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # # # # # # # # # # # # # # # # #\n",
    "\n",
    "# '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
