{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data class contains the data and extracts all the details.\n",
    "class Data():\n",
    "    def __init__(self, input_file, batch_size):\n",
    "        # type: (object, object) -> object\n",
    "        # type: (object, object) -> object\n",
    "        \"\"\"\n",
    "        :param input_file: path to the input_file\n",
    "        :param batch_size: size of the batches to use with this data\n",
    "        \"\"\"\n",
    "        data = pd.read_table(input_file)\n",
    "        data.aaMutations = data.mut_list.fillna('')\n",
    "        unique_mutations = set(':'.join(data.aaMutations).split(':'))\n",
    "        unique_mutations = sorted(list(unique_mutations))\n",
    "        if '' in unique_mutations:\n",
    "            unique_mutations.remove('')\n",
    "\n",
    "        self.data = data\n",
    "        self.unique_mutations = unique_mutations\n",
    "        self.batch_size = batch_size\n",
    "        self.input_file = input_file\n",
    "\n",
    "        self.nn_genotypes_values, self.nn_brightness_values = format_data(self)\n",
    "\n",
    "        self.nn_genotypes_test, self.nn_brightness_test, self.nn_genotypes_train, self.nn_brightness_train = \\\n",
    "            split(self)\n",
    "\n",
    "        self.batch_number = int(len(self.nn_brightness_train) / self.batch_size)\n",
    "        self.batches, self.test_batches, self.to_plot_observed, self.to_plot_observed_test = get_batches(self)\n",
    "\n",
    "        self.nn_genotypes = tf.placeholder(tf.float32, shape=[self.batch_size, 1, len(unique_mutations)])\n",
    "        self.nn_brightness = tf.placeholder(tf.float32, shape=[self.batch_size, 1, 1])\n",
    "\n",
    "    def reshuffle(self):\n",
    "        # self.nn_genotypes_test, self.nn_brightness_test, self.nn_genotypes_train, self.nn_brightness_train = \\\n",
    "        #     split(self)\n",
    "        self.batches, self.test_batches, self.to_plot_observed, self.to_plot_observed_test = get_batches(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Format data, split into feature matrix and target value vector\n",
    "def format_data(data):\n",
    "    # shuffling rows in the data df\n",
    "    unique_mutations = data.unique_mutations\n",
    "    data = data.data.reindex(np.random.permutation(data.data.index))\n",
    "\n",
    "    # formatting data for the nn input\n",
    "    print('Normalizing data...')\n",
    "    nn_genotypes_values = np.zeros((len(data), len(unique_mutations)))\n",
    "    nn_brightness_values = data.fitness.values\n",
    "    for i in range(len(unique_mutations)):\n",
    "        nn_genotypes_values[:, i] = data.mut_list.str.contains(unique_mutations[i]).astype(np.float32)\n",
    "\n",
    "    nn_brightness_values = (nn_brightness_values - min(nn_brightness_values)) / max(\n",
    "        nn_brightness_values - min(nn_brightness_values)) * 2 - 1\n",
    "\n",
    "    return nn_genotypes_values, nn_brightness_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into test and train sets randomly\n",
    "def split(data):\n",
    "    length = len(data.data)\n",
    "    test_id = np.random.randint(0, length, data.batch_size)\n",
    "    train_id = np.array([x for x in np.arange(length) if x not in test_id])\n",
    "\n",
    "    genotypes_test, genotypes_train = data.nn_genotypes_values[test_id], data.nn_genotypes_values[train_id]\n",
    "    brightness_test, brightness_train = data.nn_brightness_values[test_id], data.nn_brightness_values[train_id]\n",
    "\n",
    "    return genotypes_test, brightness_test, genotypes_train, brightness_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle train set, split train set into batches. Get train batches and test batches\n",
    "def get_batches(data):\n",
    "    length = len(data.nn_brightness_train)\n",
    "    batches = []\n",
    "    test_batches = []\n",
    "    ids = np.array([x for x in np.arange(length)])\n",
    "    to_plot_observed = []\n",
    "\n",
    "    for i in range(data.batch_number):\n",
    "        current_ids = np.random.choice(ids, data.batch_size, replace=False)\n",
    "        ids = np.array([x for x in ids if x not in current_ids])\n",
    "\n",
    "        current_batch = data.nn_genotypes_train[current_ids].reshape(data.batch_size, 1, len(data.unique_mutations))\n",
    "        current_batch_brightness = data.nn_brightness_train[current_ids].reshape(data.batch_size, 1, 1)\n",
    "        to_plot_observed.append(data.nn_brightness_train[current_ids])\n",
    "        batches.append((current_batch, current_batch_brightness))\n",
    "\n",
    "    test_batch = data.nn_genotypes_test.reshape(data.batch_size, 1, len(data.unique_mutations))\n",
    "    test_batch_brightness = data.nn_brightness_test.reshape(data.batch_size, 1, 1)\n",
    "    test_batches.append((test_batch, test_batch_brightness))\n",
    "    to_plot_observed_test = data.nn_brightness_test.reshape(data.batch_size)\n",
    "    to_plot_observed = np.array(to_plot_observed).reshape(data.batch_number * data.batch_size)\n",
    "\n",
    "    return batches, test_batches, to_plot_observed, to_plot_observed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Broadcast a tensor (used before multiplication with weights)\n",
    "def broadcast(tensor, batch_size):\n",
    "    return tf.tile(tensor, (batch_size, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the observed values versus predicted using density plot\n",
    "def density_plot(x, y, iteration_number, costs, test_score):\n",
    "    ''' x = observed, y = predicted '''\n",
    "    x = x[(~np.isnan(x)) & (~np.isnan(y))]\n",
    "    y = y[(~np.isnan(x)) & (~np.isnan(y))]\n",
    "\n",
    "    # Calculate the point density\n",
    "    xy = np.vstack([x, y])\n",
    "    z = gaussian_kde(xy)(xy)\n",
    "\n",
    "    # Sort the points by density, so that the densest points are plotted last\n",
    "    idx = z.argsort()\n",
    "    x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "    # formatting\n",
    "    plt.figure(figsize=[6, 4])\n",
    "    plt.scatter(x, y, c=z, s=3, edgecolor='', cmap='viridis_r')\n",
    "    plt.xlim(-1, 1)\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.xlabel('Observed brightness')\n",
    "    plt.ylabel('Predicted brightness')\n",
    "    plt.title('Iteration %s: cost=%.7f, EVS=%.2f' % (iteration_number, costs, test_score))\n",
    "    plt.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",\n",
    "                    labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\")\n",
    "    plt.gca().spines[\"top\"].set_visible(False)\n",
    "    plt.gca().spines[\"right\"].set_visible(False)\n",
    "    plt.gca().spines[\"bottom\"].set_color('gray')\n",
    "    plt.gca().spines[\"left\"].set_color('gray')\n",
    "    plt.gca().xaxis.grid(True)\n",
    "    plt.gca().yaxis.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input_file = '/Users/katya/Lab/CRG/Research/HIS3InterspeciesEpistasis/Analysis/Katya/NN/S5_short.txt'\n",
    "input_file = '/Users/katya/Lab/CRG/Research/GFP/data/amino_acid_genotypes_to_brightness_short.txt'\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural network class. Extracts neural net structure from the parameter file.\n",
    "# Contains all the details of the neural network to be used.\n",
    "class TFNet(object):\n",
    "    def __init__(self, net_structure, input_data, optimizer_method, learning_rate, batch_size):\n",
    "        '''\n",
    "            :param net_structure:\n",
    "                                {'layer1':(3, tf.tanh()),\n",
    "                                'layer2':((3, tf.tanh()),\n",
    "                                'layer3':(1, tf.tanh())}\n",
    "\n",
    "            :return:\n",
    "\n",
    "            https://www.tensorflow.org/versions/r0.9/api_docs/python/nn.html#activation-functions\n",
    "\n",
    "            '''\n",
    "\n",
    "        self.number_of_layers = len(net_structure)\n",
    "        self.structure = net_structure\n",
    "\n",
    "        self.neurons = {}\n",
    "        self.weights = {}\n",
    "        self.biases = {}\n",
    "        self.input = {}\n",
    "        self.output = {}\n",
    "\n",
    "        for i in range(self.number_of_layers):\n",
    "            layer = 'layer' + str(i + 1)\n",
    "            self.neurons[layer] = int(self.structure[layer][0])\n",
    "            self.weights[layer] = tf.Variable(\n",
    "                tf.random_normal([1, len(input_data.unique_mutations), self.neurons[layer]]),\n",
    "                name=layer + '_weights')\n",
    "            self.biases[layer] = tf.Variable(tf.random_normal([1, 1, self.neurons[layer]]), name=layer + '_biases')\n",
    "            self.input[layer] = tf.add(\n",
    "                tf.matmul(input_data.nn_genotypes, broadcast(self.weights[layer], batch_size)),\n",
    "                broadcast(self.biases[layer], batch_size))\n",
    "            self.output[layer] = eval(self.structure[layer][1])(self.input[layer])\n",
    "\n",
    "        weights = [(self.weights[x]) for x in ['layer1', 'layer2', 'layer3']]\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(0.001)\n",
    "\n",
    "        self.cost = tf.reduce_sum(tf.pow(self.output[layer] - input_data.nn_brightness, 2)) / batch_size\n",
    "        self.cost = tf.reduce_mean(self.cost + tf.contrib.layers.apply_regularization(regularizer, weights))\n",
    "        self.optimizer = eval(optimizer_method)(learning_rate).minimize(self.cost)\n",
    "\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "    def __str__(self):\n",
    "        print('Net structure:\\n')\n",
    "        for i in range(self.number_of_layers):\n",
    "            print('%s neurons in layer_' % (self.neurons['layer' + str(i + 1)]) + str(i + 1) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "optimizer_method = 'tf.train.AdagradOptimizer'\n",
    "line = 'net_structure\\t1,tf.tanh\\t10,tf.tanh\\t1,tf.tanh'\n",
    "net_structure = {}\n",
    "counter = 1\n",
    "for i in line.split('\\t')[1:]:\n",
    "    net_structure['layer' + str(counter)] = i.split(',')\n",
    "    counter += 1\n",
    "    \n",
    "max_epochs = 400\n",
    "reshuffling_frequency = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing data...\n"
     ]
    }
   ],
   "source": [
    "data = Data(input_file, batch_size)\n",
    "net = TFNet(net_structure, data, optimizer_method, learning_rate, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initializing variables\n",
    "    sess.run(net.init)\n",
    "\n",
    "    # Initiating the session run for a specified number of iterations.\n",
    "    for e in range(max_epochs):\n",
    "        for batch, batch_brightness in data.batches:\n",
    "            sess.run(net.optimizer, feed_dict={data.nn_genotypes: batch, data.nn_brightness: batch_brightness})\n",
    "            \n",
    "    # Write down the outputs every 10th iteration.\n",
    "        if e % 10 == 0:\n",
    "\n",
    "            # Extracting net cost function output.\n",
    "            to_plot_predicted = np.zeros(data.batch_number * batch_size)\n",
    "        \n",
    "        \n",
    "            for index, (batch, batch_brightness) in enumerate(data.batches):\n",
    "                cost_value, l3_value = sess.run([net.cost, net.output['layer3']],\n",
    "                                                feed_dict={data.nn_genotypes: batch,\n",
    "                                                           data.nn_brightness: batch_brightness})\n",
    "\n",
    "                to_plot_predicted[(index * batch_size):((index + 1) * batch_size)] = l3_value.reshape(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (0,) (900,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-c2bc08911738>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdensity_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_plot_observed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_plot_predicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-145-983924cbac1b>\u001b[0m in \u001b[0;36mdensity_plot\u001b[0;34m(x, y, iteration_number, costs, test_score)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m''' x = observed, y = predicted '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Calculate the point density\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (0,) (900,) "
     ]
    }
   ],
   "source": [
    "density_plot(np.array(data.to_plot_observed), to_plot_predicted, e, cost_value, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900,)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data.to_plot_observed).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_plot_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
