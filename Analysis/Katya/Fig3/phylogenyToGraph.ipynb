{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "clean_data = {}\n",
    "\n",
    "for f in os.listdir('/home/katya/start/HIS3InterspeciesEpistasis/Data/'):\n",
    "    if 'csv' in f:\n",
    "        data[f[:-19]] = pd.DataFrame.from_csv('/home/katya/start/HIS3InterspeciesEpistasis/Data/' + f, sep='\\t')\n",
    "        median = np.median(data[f[:-19]].index.str.len())\n",
    "        \n",
    "        clean_data[f[:-19]] = data[f[:-19]][(data[f[:-19]].nonsense == 0) & (data[f[:-19]].middle == 1) & \\\n",
    "                                            (data[f[:-19]].nat_lib == 1) & (data[f[:-19]].stop == 0) & \\\n",
    "                                            (data[f[:-19]].index.str.len() == median)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source = ['23','23','23','24','24','40','40','41','41','25','25','26','26','27','27','28','28','34','34','35','35','36','36','37','37','38','38','39','39','29','29','30','30','31','31','32','32','33','33']\n",
    "target = ['Ylip','Anid','24','40','25','Sjap','41','Soct','Spom','Ncra','26','Agos','27','Cgla','28','29','34','Cgui','35','36','37','Clus','Dhan','38','39','Calb','Ctro','Cpar','Lelo','30','32','Scas','31','Scer','Sbay','Klac','33','Kwal','Sklu']\n",
    "\n",
    "nodes = list(source)\n",
    "nodes.extend(target)\n",
    "nodes = list(set(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "location = {}\n",
    "for node in nodes:\n",
    "    location[node] = {}\n",
    "    location[node]['x'] = np.random.randint(1000)\n",
    "    location[node]['y'] = np.random.randint(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunks = ['S'+str(i) for i in range(1,13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1\n",
      "S2\n",
      "S3\n",
      "S4\n",
      "S5\n",
      "S6\n",
      "S7\n",
      "S8\n",
      "S9\n",
      "S10\n",
      "S11\n",
      "S12\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    print chunk\n",
    "    data = {}\n",
    "    data['nodes'] = []\n",
    "    for node in nodes:\n",
    "\n",
    "            if node.isdigit():\n",
    "                if len(clean_data[chunk][clean_data[chunk]['dist_node_'+node]==0])!=0:\n",
    "                    fitness = float(clean_data[chunk][clean_data[chunk]['dist_node_'+node]==0].s)\n",
    "                    data['nodes'].append({'id':node, 'fitness':fitness, 'x': location[node]['x'], \n",
    "                                          'y': location[node]['y'], 'group':0})\n",
    "\n",
    "                else:\n",
    "                    fitness = 0.45\n",
    "                    data['nodes'].append({'id':node, 'fitness':fitness, 'x': location[node]['x'], \n",
    "                                          'y': location[node]['y'], 'group':2})\n",
    "                    \n",
    "            else:\n",
    "                \n",
    "                if len(clean_data[chunk][clean_data[chunk]['dist_'+node]==0])!=0:\n",
    "                    fitness = float(clean_data[chunk][clean_data[chunk]['dist_'+node]==0].s)\n",
    "                    data['nodes'].append({'id':node, 'fitness':fitness, 'x': location[node]['x'], \n",
    "                                          'y': location[node]['y'],  'group':0})\n",
    "\n",
    "                else:\n",
    "                    fitness = 0.45\n",
    "                    data['nodes'].append({'id':node, 'fitness':fitness, 'x': location[node]['x'], \n",
    "                                          'y': location[node]['y'], 'group':2})\n",
    "            \n",
    "    data['links'] = []\n",
    "\n",
    "    for i in range(len(source)):\n",
    "        data['links'].append({'source':source[i], 'target':target[i], 'group':0})\n",
    "\n",
    "######################################################################################################################        \n",
    "        \n",
    "    tempNodes = []\n",
    "    tempNodes2 = []\n",
    "\n",
    "    for node in nodes:\n",
    "        if node.isdigit():\n",
    "            nodeList = clean_data[chunk][clean_data[chunk]['dist_node_'+node]==1].index\n",
    "            for sq1 in nodeList:\n",
    "                if sq1+node+'1' not in tempNodes:\n",
    "                    tempNodes.append(sq1+node+'1')\n",
    "                    data['nodes'].append({'id':sq1+node+'1', 'fitness':clean_data[chunk].ix[sq1].s, 'group':1})\n",
    "                data['links'].append({'source':node, 'target':sq1+node+'1', 'group':1})\n",
    "                \n",
    "#                 nodeList2 = clean_data[chunk][clean_data[chunk]['dist_node_'+node]==2].index\n",
    "#                 for sq2 in nodeList2:\n",
    "#                     if distance.hamming(sq1,sq2) == 1:\n",
    "#                         if sq2+'_'+sq1+node+'2' not in tempNodes2:\n",
    "#                             tempNodes2.append(sq2+'_'+sq1+node+'2')\n",
    "#                             data['nodes'].append({'id':sq2+'_'+sq1+node+'2', \n",
    "#                                                   'fitness':clean_data[chunk].ix[sq2].s, 'group':3})\n",
    "#                         data['links'].append({'source':sq1+node+'1', 'target':sq2+'_'+sq1+node+'2', 'group':3})\n",
    "\n",
    "        else:\n",
    "            nodeList = clean_data[chunk][clean_data[chunk]['dist_'+node]==1].index\n",
    "            for sq1 in nodeList:\n",
    "                if sq1+node+'1' not in tempNodes:\n",
    "                    tempNodes.append(sq1+node+'1')\n",
    "                    data['nodes'].append({'id':sq1+node+'1', 'fitness':clean_data[chunk].ix[sq1].s, 'group':1})\n",
    "                data['links'].append({'source':node, 'target':sq1+node+'1', 'group':1})\n",
    "                \n",
    "    with open('/home/katya/start/HIS3InterspeciesEpistasis/Analysis/Katya/Fig3/' + chunk + '.json', 'w+') as outfile:  \n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
